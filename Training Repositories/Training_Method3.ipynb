{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_Method3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ByHssqkiXbbkPmyueAr3bhPePRq2WjLe",
      "authorship_tag": "ABX9TyM5mSscBlvESZVONo9/JUm5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raulbenitez/CHESS_ROBOT/blob/master/Training%20Repositories/Training_Method3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiIXq9DIscCB",
        "colab_type": "text"
      },
      "source": [
        "#Set environment and networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haZljF-5sgO5",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries and datasets:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNCbjzf--X8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import cv2\n",
        "\n",
        "#Input Keras and Tensorflow Environment\n",
        "%tensorflow_version 1.15.0\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, utils, regularizers, applications\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"\\nEnviornments imported\")\n",
        "\n",
        "folder = './dataset'\n",
        "!unzip -q \"./drive/My Drive/dataset-v3.zip\" -d \"dataset\"\n",
        "\n",
        "print(\"\\nDataset loaded\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMhZ9z7NsnKL",
        "colab_type": "text"
      },
      "source": [
        "**Load CNN and remove top layers:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw_UgYSooz3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_model = 'vgg19_tfm.h5'\n",
        "folder_model = 'drive/My Drive/TFM/models/vggmodel19_cam2_v1.h5'\n",
        "vggmodel19 = models.load_model(folder_model)\n",
        "    \n",
        "episodes = 100   \n",
        "vggmodel19.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "vggmodel19.summary()\n",
        "\n",
        "vggmodel19.save('final.h5')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjf6NpGtcMGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "for layer in vggmodel19.layers[:-3]: # go through until last layer\n",
        "    model.add(layer)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.save('vggmodel19.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTPUlRs5s5J7",
        "colab_type": "text"
      },
      "source": [
        "**Load dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vMRuH5krGO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"2. Create dataset:\\n\")\n",
        "\n",
        "train_folder = folder + '/train'\n",
        "test_folder = folder + '/validate'\n",
        "\n",
        "print(train_folder)\n",
        "print(test_folder)\n",
        "\n",
        "clases = [\"-\", \"BB\", \"BK\", \"BN\", \"BP\", \"BQ\", \"BR\", \"WB\", \"WK\", \"WN\", \"WP\", \"WQ\", \"WR\"]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQt6VWB0tAuN",
        "colab_type": "text"
      },
      "source": [
        "#Creating and Training the SVM:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U4KcKqgtJDJ",
        "colab_type": "text"
      },
      "source": [
        "**Use CNN as feature extracture:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxSj-fDJscyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_max = 775\n",
        "\n",
        "feat_train = []\n",
        "pred_train = []\n",
        "true_train = []\n",
        "\n",
        "dim = (224, 224)\n",
        "\n",
        "for i in range(0,len(clases)):\n",
        "\n",
        "  cl = clases[i]\n",
        "  fld = train_folder + '/' + cl\n",
        "\n",
        "\n",
        "  for n in range(1,img_max):  \n",
        "\n",
        "    fl = fld +\"/im (\" + str(n) +\").jpg\"\n",
        "\n",
        "    try: \n",
        "      img = image.load_img(fl)\n",
        "      img = image.img_to_array(img)\n",
        "      img = cv2.resize(img,dim)\n",
        "      img = np.expand_dims(img/255., axis=0)\n",
        "\n",
        "      pred = model.predict(img)\n",
        "      feat_train.append(pred)\n",
        "      pred_train.append(np.argmax(pred))\n",
        "      true_train.append(i)\n",
        "    \n",
        "    except:\n",
        "      print(\"error loading img\")\n",
        "\n",
        "\n",
        "print(np.shape(feat_train))\n",
        "print(\"Train files predicted\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcO3nZd9r8Nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_max = 175\n",
        "\n",
        "feat_test = []\n",
        "pred_test = []\n",
        "true_test = []\n",
        "\n",
        "dim = (224, 224)\n",
        "\n",
        "for i in range(0,len(clases)):\n",
        "\n",
        "  cl = clases[i]\n",
        "  fld = train_folder + '/' + cl\n",
        "\n",
        "  for n in range(1,img_max):  \n",
        "\n",
        "    fl = fld +\"/im (\" + str(n) +\").jpg\"\n",
        "\n",
        "    try: \n",
        "      img = image.load_img(fl)\n",
        "      img = image.img_to_array(img)\n",
        "      img = cv2.resize(img,dim)\n",
        "      img = np.expand_dims(img/255., axis=0)\n",
        "\n",
        "      pred = model.predict(img)\n",
        "      predcnn = vggmodel19.predict(img)\n",
        "      feat_test.append(pred.flatten())\n",
        "      pred_test.append(np.argmax(predcnn))\n",
        "      true_test.append(i)\n",
        "\n",
        "    except:\n",
        "      print(\"Image load error\") \n",
        "\n",
        "print(np.shape(feat_test))\n",
        "print(\"Test files predicted\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YhU-KtsttWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b6051e84-a8cb-4131-ba87-d70b010bfa6f"
      },
      "source": [
        "feat_test = np.squeeze(feat_test)\n",
        "feat_train = np.squeeze(feat_train)\n",
        "\n",
        "true_train = np.squeeze(true_train)\n",
        "pred_train = np.squeeze(pred_train)\n",
        "\n",
        "true_test = np.squeeze(true_test)\n",
        "pred_test = np.squeeze(pred_test)\n",
        "\n",
        "print(\"Train: \", np.shape(true_train), np.shape(pred_train))\n",
        "print(\"Test: \", np.shape(true_test), np.shape(pred_test))\n",
        "print(\"Feats:\", np.shape(feat_test), np.shape(feat_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  (10062,) (10062,)\n",
            "Test:  (2262,) (2262,)\n",
            "Feats: (2262, 1024) (10062, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZkdfEUKtV6t",
        "colab_type": "text"
      },
      "source": [
        "**Fit SVM:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHnvTGitA_Kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
        "\n",
        "clf1 = SVC(kernel='linear', class_weight='balanced',gamma=0.001)\n",
        "ddtrain = np.squeeze(feat_train)\n",
        "clf1 = clf1.fit(ddtrain, true_train)\n",
        "\n",
        "print(clf1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWNyDBzktqtK",
        "colab_type": "text"
      },
      "source": [
        "**Test SVM:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-EghMCKBEsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ddtest = feat_test\n",
        "pred_svm = clf1.predict(ddtest)\n",
        "\n",
        "print(\"SVM Results: \")\n",
        "print(classification_report(true_test, pred_svm))\n",
        "print(confusion_matrix(true_test, pred_svm))\n",
        "\n",
        "print(\"\\n\\nCNN Results: \")\n",
        "print(classification_report(true_test, pred_test))\n",
        "print(confusion_matrix(true_test, pred_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xqPrmantyX2",
        "colab_type": "text"
      },
      "source": [
        "**Save SVM model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCejJnJpgOjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "# Save to file in the current working directory\n",
        "joblib_file = \"drive/My Drive/TFM/models/svm_tfm.pkl\"\n",
        "joblib_file = \"svm_tfm_final.pkl\"\n",
        "joblib.dump(clf1, joblib_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UYQmakguRrO",
        "colab_type": "text"
      },
      "source": [
        "**Optimizing with Grid Search:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBBVHUkryVvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
        "svm = SVC()\n",
        "grid_search = GridSearchCV(svm, parameters)\n",
        "grid_search.fit(ddtrain, true_train)\n",
        "grid_search.best_estimator_\n",
        "\n",
        "print(grid_search)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9wa--xjuYo0",
        "colab_type": "text"
      },
      "source": [
        "**Save model from Grid Search:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vviqbb_z5zF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ddtest = feat_test\n",
        "pred_svm = clf1.predict(ddtest)\n",
        "pred_gs = grid_search.predict(ddtest)\n",
        "\n",
        "print(\"SVM with Grid Search predicted\")\n",
        "\n",
        "# Save to file in the current working directory\n",
        "joblib_file = \"drive/My Drive/TFM/models/gridsearch_tfm.pkl\"\n",
        "joblib.dump(grid_search, joblib_file)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq_w-IBauhWB",
        "colab_type": "text"
      },
      "source": [
        "#Testing and comparing results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQqjnxomukpt",
        "colab_type": "text"
      },
      "source": [
        "**Generating confusion matrices:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwk7IiVzlLdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "success = 0\n",
        "success_svm = 0\n",
        "success_gs = 0\n",
        "success_top3 = 0\n",
        "total = 0\n",
        "ang = 0\n",
        "img_max = 175\n",
        "dim = (224, 224)\n",
        "\n",
        "correct_answer = []\n",
        "cnn_result = []\n",
        "svm_result = []\n",
        "gs_result = []\n",
        "\n",
        "for lbl in clases:\n",
        "\n",
        "    for n in range(1,img_max+1):\n",
        "\n",
        "            file = test_folder +'/'+ lbl + \"/im (\" + str(n) +\").jpg\"\n",
        "\n",
        "            img = image.load_img(file)\n",
        "            img = image.img_to_array(img)\n",
        "            img = cv2.resize(img,dim)\n",
        "            img = np.expand_dims(img/255., axis=0)\n",
        "\n",
        "            pred = vggmodel19.predict(img, batch_size = 1)\n",
        "            feat = model.predict(img, batch_size = 1)\n",
        "\n",
        "            ind = np.argsort(pred)[0][-3:]\n",
        "\n",
        "            top1 = clases[ind[2]]\n",
        "            top3 = [clases[ind[0]], clases[ind[1]], clases[ind[2]]]\n",
        "\n",
        "            if lbl == top1:\n",
        "                success += 1\n",
        "            if lbl in top3:\n",
        "                success_top3 += 1\n",
        "\n",
        "            dd = np.expand_dims(np.squeeze(feat.flatten()), axis=0)\n",
        "            pred_svm1 = clf1.predict(dd)\n",
        "            pred_gs = grid_search.predict(dd)\n",
        "\n",
        "            top1_svm = clases[pred_svm1[0]]\n",
        "            top1_gs = clases[pred_gs[0]]\n",
        "\n",
        "            if lbl == top1_svm:\n",
        "                success_svm += 1\n",
        "            if lbl == top1_gs:\n",
        "              success_gs += 1\n",
        "\n",
        "            total +=1\n",
        "\n",
        "            correct_answer.append(lbl)\n",
        "            cnn_result.append(top1)\n",
        "            svm_result.append(top1_svm)\n",
        "            gs_result.append(top1_gs)\n",
        "\n",
        "\n",
        "print(\"\\nSuccess rate: \", 100*success/total, \"% of \", total, \" images.\" )\n",
        "print(\"Success rate with SVM: \", 100*success_svm/total, \"% of \", total, \" images.\" )\n",
        "print(\"Success rate with Grid Search: \", 100*success_gs/total, \"% of \", total, \" images.\" )\n",
        "print(\"Success rate of top 3: \", 100*success_top3/total, \"% of \", total, \" images.\\n\" )\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufZkFvbtVM_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cf_matrix_svm = confusion_matrix(correct_answer, svm_result)\n",
        "cf_matrix_gs = confusion_matrix(correct_answer, gs_result)\n",
        "cf_matrix_cnn = confusion_matrix(correct_answer, cnn_result)\n",
        "\n",
        "print(\"CNN Results: \")\n",
        "print(cf_matrix_cnn)\n",
        "print(\"\\nSVM Results: \")\n",
        "print(cf_matrix_svm)\n",
        "print(\"\\nGrid Search Results: \")\n",
        "print(cf_matrix_gs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWeScst7u511",
        "colab_type": "text"
      },
      "source": [
        "**Saving Results:** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7LoQuLyOP00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "df_cm_svm = pd.DataFrame(cf_matrix_svm, columns=np.unique(clases), index = np.unique(clases),)\n",
        "df_cm_svm.index.name = 'Actual'\n",
        "df_cm_svm.columns.name = 'Predicted SVM'\n",
        "\n",
        "df_cm_gs = pd.DataFrame(cf_matrix_gs, columns=np.unique(clases), index = np.unique(clases))\n",
        "df_cm_gs.index.name = 'Actual'\n",
        "df_cm_gs.columns.name = 'Predicted GS'\n",
        "\n",
        "df_cm_cnn = pd.DataFrame(cf_matrix_cnn, columns=np.unique(clases), index = np.unique(clases))\n",
        "df_cm_cnn.index.name = 'Actual'\n",
        "df_cm_cnn.columns.name = 'Predicted CNN'\n",
        "\n",
        "columns = {}\n",
        "columns['Actual'] = true_test\n",
        "columns['Predicted SVM'] = svm_result\n",
        "columns['Predicted CNN'] = cnn_result\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(df_cm_svm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16}, fmt='g',ax=ax)# font size\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(df_cm_gs, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16}, fmt='g',ax=ax)# font size\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(df_cm_cnn, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16}, fmt='g',ax=ax)# font size\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}