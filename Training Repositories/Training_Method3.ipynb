{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_Method3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ByHssqkiXbbkPmyueAr3bhPePRq2WjLe",
      "authorship_tag": "ABX9TyM5mSscBlvESZVONo9/JUm5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raulbenitez/CHESS_ROBOT/blob/master/Training%20Repositories/Training_Method3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiIXq9DIscCB",
        "colab_type": "text"
      },
      "source": [
        "#Set environment and networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haZljF-5sgO5",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries and datasets:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNCbjzf--X8c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "c8d11e2b-09d6-429e-ef84-fdf656d09251"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import cv2\n",
        "\n",
        "#Input Keras and Tensorflow Environment\n",
        "%tensorflow_version 1.15.0\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, utils, regularizers, applications\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"\\nEnviornments imported\")\n",
        "\n",
        "folder = './dataset'\n",
        "!unzip -q \"./drive/My Drive/dataset-v3.zip\" -d \"dataset\"\n",
        "\n",
        "print(\"\\nDataset loaded\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "1.15.2\n",
            "\n",
            "Enviornments imported\n",
            "replace dataset/validate/-/im (1).jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "\n",
            "Dataset loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMhZ9z7NsnKL",
        "colab_type": "text"
      },
      "source": [
        "**Load CNN and remove top layers:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw_UgYSooz3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e43f2b2-cbf5-430e-c788-ee17174becef"
      },
      "source": [
        "folder_model = 'vgg19_tfm.h5'\n",
        "folder_model = 'drive/My Drive/TFM/models/vggmodel19_cam2_v1.h5'\n",
        "vggmodel19 = models.load_model(folder_model)\n",
        "    \n",
        "episodes = 100   \n",
        "vggmodel19.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "vggmodel19.summary()\n",
        "\n",
        "vggmodel19.save('final.h5')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 13)                13325     \n",
            "=================================================================\n",
            "Total params: 21,612,621\n",
            "Trainable params: 6,307,853\n",
            "Non-trainable params: 15,304,768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjf6NpGtcMGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "outputId": "921d54f6-4133-4623-a2ff-057ef090a438"
      },
      "source": [
        "model = models.Sequential()\n",
        "for layer in vggmodel19.layers[:-3]: # go through until last layer\n",
        "    model.add(layer)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.save('vggmodel19.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              525312    \n",
            "=================================================================\n",
            "Total params: 20,549,696\n",
            "Trainable params: 5,244,928\n",
            "Non-trainable params: 15,304,768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTPUlRs5s5J7",
        "colab_type": "text"
      },
      "source": [
        "**Load dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vMRuH5krGO1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "c6870187-0339-463a-99b5-eef1259c7bf6"
      },
      "source": [
        "print(\"2. Create dataset:\\n\")\n",
        "\n",
        "train_folder = folder + '/train'\n",
        "test_folder = folder + '/validate'\n",
        "\n",
        "print(train_folder)\n",
        "print(test_folder)\n",
        "\n",
        "clases = [\"-\", \"BB\", \"BK\", \"BN\", \"BP\", \"BQ\", \"BR\", \"WB\", \"WK\", \"WN\", \"WP\", \"WQ\", \"WR\"]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2. Create dataset:\n",
            "\n",
            "./dataset/train\n",
            "./dataset/validate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQt6VWB0tAuN",
        "colab_type": "text"
      },
      "source": [
        "#Creating and Training the SVM:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U4KcKqgtJDJ",
        "colab_type": "text"
      },
      "source": [
        "**Use CNN as feature extracture:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxSj-fDJscyM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e9b250c5-ec28-4795-83ea-d362f11871d3"
      },
      "source": [
        "img_max = 775\n",
        "\n",
        "feat_train = []\n",
        "pred_train = []\n",
        "true_train = []\n",
        "\n",
        "dim = (224, 224)\n",
        "\n",
        "for i in range(0,len(clases)):\n",
        "\n",
        "  cl = clases[i]\n",
        "  fld = train_folder + '/' + cl\n",
        "\n",
        "\n",
        "  for n in range(1,img_max):  \n",
        "\n",
        "    fl = fld +\"/im (\" + str(n) +\").jpg\"\n",
        "\n",
        "    try: \n",
        "      img = image.load_img(fl)\n",
        "      img = image.img_to_array(img)\n",
        "      img = cv2.resize(img,dim)\n",
        "      img = np.expand_dims(img/255., axis=0)\n",
        "\n",
        "      pred = model.predict(img)\n",
        "      feat_train.append(pred)\n",
        "      pred_train.append(np.argmax(pred))\n",
        "      true_train.append(i)\n",
        "    \n",
        "    except:\n",
        "      print(\"error loading img\")\n",
        "\n",
        "\n",
        "print(np.shape(feat_train))\n",
        "print(\"Train files predicted\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10062, 1, 1024)\n",
            "Train files predicted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcO3nZd9r8Nl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5b8747b1-eb3a-49c0-a6ca-5330993bce8f"
      },
      "source": [
        "img_max = 175\n",
        "\n",
        "feat_test = []\n",
        "pred_test = []\n",
        "true_test = []\n",
        "\n",
        "dim = (224, 224)\n",
        "\n",
        "for i in range(0,len(clases)):\n",
        "\n",
        "  cl = clases[i]\n",
        "  fld = train_folder + '/' + cl\n",
        "\n",
        "  for n in range(1,img_max):  \n",
        "\n",
        "    fl = fld +\"/im (\" + str(n) +\").jpg\"\n",
        "\n",
        "    try: \n",
        "      img = image.load_img(fl)\n",
        "      img = image.img_to_array(img)\n",
        "      img = cv2.resize(img,dim)\n",
        "      img = np.expand_dims(img/255., axis=0)\n",
        "\n",
        "      pred = model.predict(img)\n",
        "      predcnn = vggmodel19.predict(img)\n",
        "      feat_test.append(pred.flatten())\n",
        "      pred_test.append(np.argmax(predcnn))\n",
        "      true_test.append(i)\n",
        "\n",
        "    except:\n",
        "      print(\"Image load error\") \n",
        "\n",
        "print(np.shape(feat_test))\n",
        "print(\"Test files predicted\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2262, 1024)\n",
            "Test files predicted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YhU-KtsttWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b6051e84-a8cb-4131-ba87-d70b010bfa6f"
      },
      "source": [
        "feat_test = np.squeeze(feat_test)\n",
        "feat_train = np.squeeze(feat_train)\n",
        "\n",
        "true_train = np.squeeze(true_train)\n",
        "pred_train = np.squeeze(pred_train)\n",
        "\n",
        "true_test = np.squeeze(true_test)\n",
        "pred_test = np.squeeze(pred_test)\n",
        "\n",
        "print(\"Train: \", np.shape(true_train), np.shape(pred_train))\n",
        "print(\"Test: \", np.shape(true_test), np.shape(pred_test))\n",
        "print(\"Feats:\", np.shape(feat_test), np.shape(feat_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  (10062,) (10062,)\n",
            "Test:  (2262,) (2262,)\n",
            "Feats: (2262, 1024) (10062, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZkdfEUKtV6t",
        "colab_type": "text"
      },
      "source": [
        "**Fit SVM:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHnvTGitA_Kz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "6cb3a6fa-6bba-4868-c440-55e35d4a8785"
      },
      "source": [
        "from keras.models import Model\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
        "\n",
        "clf1 = SVC(kernel='linear', class_weight='balanced',gamma=0.001)\n",
        "ddtrain = np.squeeze(feat_train)\n",
        "clf1 = clf1.fit(ddtrain, true_train)\n",
        "\n",
        "print(clf1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWNyDBzktqtK",
        "colab_type": "text"
      },
      "source": [
        "**Test SVM:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-EghMCKBEsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af9290a6-8a01-4906-b9b6-f711f6def0c8"
      },
      "source": [
        "ddtest = feat_test\n",
        "pred_svm = clf1.predict(ddtest)\n",
        "\n",
        "print(\"SVM Results: \")\n",
        "print(classification_report(true_test, pred_svm))\n",
        "print(confusion_matrix(true_test, pred_svm))\n",
        "\n",
        "print(\"\\n\\nCNN Results: \")\n",
        "print(classification_report(true_test, pred_test))\n",
        "print(confusion_matrix(true_test, pred_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Results: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       174\n",
            "           1       1.00      0.99      1.00       174\n",
            "           2       0.99      1.00      1.00       174\n",
            "           3       0.99      0.99      0.99       174\n",
            "           4       1.00      0.99      0.99       174\n",
            "           5       1.00      1.00      1.00       174\n",
            "           6       0.99      1.00      0.99       174\n",
            "           7       1.00      1.00      1.00       174\n",
            "           8       1.00      1.00      1.00       174\n",
            "           9       1.00      1.00      1.00       174\n",
            "          10       1.00      1.00      1.00       174\n",
            "          11       1.00      1.00      1.00       174\n",
            "          12       1.00      1.00      1.00       174\n",
            "\n",
            "    accuracy                           1.00      2262\n",
            "   macro avg       1.00      1.00      1.00      2262\n",
            "weighted avg       1.00      1.00      1.00      2262\n",
            "\n",
            "[[174   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 173   0   0   0   0   1   0   0   0   0   0   0]\n",
            " [  0   0 174   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   1 173   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   1 172   0   1   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 174   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 174   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 174   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 174   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 174   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 174   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 174   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 174]]\n",
            "\n",
            "\n",
            "CNN Results: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       174\n",
            "           1       0.98      0.99      0.98       174\n",
            "           2       0.89      0.98      0.93       174\n",
            "           3       0.98      0.98      0.98       174\n",
            "           4       0.99      0.86      0.92       174\n",
            "           5       0.99      0.96      0.98       174\n",
            "           6       0.94      0.98      0.96       174\n",
            "           7       0.99      0.97      0.98       174\n",
            "           8       0.98      0.99      0.99       174\n",
            "           9       0.99      0.99      0.99       174\n",
            "          10       1.00      0.99      1.00       174\n",
            "          11       0.98      0.99      0.99       174\n",
            "          12       1.00      1.00      1.00       174\n",
            "\n",
            "    accuracy                           0.98      2262\n",
            "   macro avg       0.98      0.98      0.98      2262\n",
            "weighted avg       0.98      0.98      0.98      2262\n",
            "\n",
            "[[174   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 172   0   0   1   0   1   0   0   0   0   0   0]\n",
            " [  1   2 170   0   0   0   0   0   1   0   0   0   0]\n",
            " [  0   0   2 171   0   0   1   0   0   0   0   0   0]\n",
            " [  0   1  12   3 150   0   8   0   0   0   0   0   0]\n",
            " [  0   1   5   1   0 167   0   0   0   0   0   0   0]\n",
            " [  0   0   3   0   0   0 171   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 168   3   1   0   2   0]\n",
            " [  0   0   0   0   0   0   0   0 173   1   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 173   0   1   0]\n",
            " [  0   0   0   0   0   0   0   1   0   0 173   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 174]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xqPrmantyX2",
        "colab_type": "text"
      },
      "source": [
        "**Save SVM model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCejJnJpgOjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "9a93d14c-a544-4cd0-e316-1a8ddd7156b1"
      },
      "source": [
        "\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "# Save to file in the current working directory\n",
        "joblib_file = \"drive/My Drive/TFM/models/svm_tfm.pkl\"\n",
        "joblib_file = \"svm_tfm_final.pkl\"\n",
        "joblib.dump(clf1, joblib_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['svm_tfm_final.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UYQmakguRrO",
        "colab_type": "text"
      },
      "source": [
        "**Optimizing with Grid Search:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBBVHUkryVvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "de501ded-ac79-4e91-9499-51dfa6f92669"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
        "svm = SVC()\n",
        "grid_search = GridSearchCV(svm, parameters)\n",
        "grid_search.fit(ddtrain, true_train)\n",
        "grid_search.best_estimator_\n",
        "\n",
        "print(grid_search)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=None, error_score=nan,\n",
            "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
            "                           class_weight=None, coef0=0.0,\n",
            "                           decision_function_shape='ovr', degree=3,\n",
            "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
            "                           probability=False, random_state=None, shrinking=True,\n",
            "                           tol=0.001, verbose=False),\n",
            "             iid='deprecated', n_jobs=None,\n",
            "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=None, verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9wa--xjuYo0",
        "colab_type": "text"
      },
      "source": [
        "**Save model from Grid Search:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vviqbb_z5zF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ddtest = feat_test\n",
        "pred_svm = clf1.predict(ddtest)\n",
        "pred_gs = grid_search.predict(ddtest)\n",
        "\n",
        "print(\"SVM with Grid Search predicted\")\n",
        "\n",
        "# Save to file in the current working directory\n",
        "joblib_file = \"drive/My Drive/TFM/models/gridsearch_tfm.pkl\"\n",
        "joblib.dump(grid_search, joblib_file)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq_w-IBauhWB",
        "colab_type": "text"
      },
      "source": [
        "#Testing and comparing results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQqjnxomukpt",
        "colab_type": "text"
      },
      "source": [
        "**Generating confusion matrices:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwk7IiVzlLdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "success = 0\n",
        "success_svm = 0\n",
        "success_gs = 0\n",
        "success_top3 = 0\n",
        "total = 0\n",
        "ang = 0\n",
        "img_max = 175\n",
        "dim = (224, 224)\n",
        "\n",
        "correct_answer = []\n",
        "cnn_result = []\n",
        "svm_result = []\n",
        "gs_result = []\n",
        "\n",
        "for lbl in clases:\n",
        "\n",
        "    for n in range(1,img_max+1):\n",
        "\n",
        "            file = test_folder +'/'+ lbl + \"/im (\" + str(n) +\").jpg\"\n",
        "\n",
        "            img = image.load_img(file)\n",
        "            img = image.img_to_array(img)\n",
        "            img = cv2.resize(img,dim)\n",
        "            img = np.expand_dims(img/255., axis=0)\n",
        "\n",
        "            pred = vggmodel19.predict(img, batch_size = 1)\n",
        "            feat = model.predict(img, batch_size = 1)\n",
        "\n",
        "            ind = np.argsort(pred)[0][-3:]\n",
        "\n",
        "            top1 = clases[ind[2]]\n",
        "            top3 = [clases[ind[0]], clases[ind[1]], clases[ind[2]]]\n",
        "\n",
        "            if lbl == top1:\n",
        "                success += 1\n",
        "            if lbl in top3:\n",
        "                success_top3 += 1\n",
        "\n",
        "            dd = np.expand_dims(np.squeeze(feat.flatten()), axis=0)\n",
        "            pred_svm1 = clf1.predict(dd)\n",
        "            pred_gs = grid_search.predict(dd)\n",
        "\n",
        "            top1_svm = clases[pred_svm1[0]]\n",
        "            top1_gs = clases[pred_gs[0]]\n",
        "\n",
        "            if lbl == top1_svm:\n",
        "                success_svm += 1\n",
        "            if lbl == top1_gs:\n",
        "              success_gs += 1\n",
        "\n",
        "            total +=1\n",
        "\n",
        "            correct_answer.append(lbl)\n",
        "            cnn_result.append(top1)\n",
        "            svm_result.append(top1_svm)\n",
        "            gs_result.append(top1_gs)\n",
        "\n",
        "\n",
        "print(\"\\nSuccess rate: \", 100*success/total, \"% of \", total, \" images.\" )\n",
        "print(\"Success rate with SVM: \", 100*success_svm/total, \"% of \", total, \" images.\" )\n",
        "print(\"Success rate with Grid Search: \", 100*success_gs/total, \"% of \", total, \" images.\" )\n",
        "print(\"Success rate of top 3: \", 100*success_top3/total, \"% of \", total, \" images.\\n\" )\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufZkFvbtVM_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cf_matrix_svm = confusion_matrix(correct_answer, svm_result)\n",
        "cf_matrix_gs = confusion_matrix(correct_answer, gs_result)\n",
        "cf_matrix_cnn = confusion_matrix(correct_answer, cnn_result)\n",
        "\n",
        "print(\"CNN Results: \")\n",
        "print(cf_matrix_cnn)\n",
        "print(\"\\nSVM Results: \")\n",
        "print(cf_matrix_svm)\n",
        "print(\"\\nGrid Search Results: \")\n",
        "print(cf_matrix_gs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWeScst7u511",
        "colab_type": "text"
      },
      "source": [
        "**Saving Results:** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7LoQuLyOP00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "df_cm_svm = pd.DataFrame(cf_matrix_svm, columns=np.unique(clases), index = np.unique(clases),)\n",
        "df_cm_svm.index.name = 'Actual'\n",
        "df_cm_svm.columns.name = 'Predicted SVM'\n",
        "\n",
        "df_cm_gs = pd.DataFrame(cf_matrix_gs, columns=np.unique(clases), index = np.unique(clases))\n",
        "df_cm_gs.index.name = 'Actual'\n",
        "df_cm_gs.columns.name = 'Predicted GS'\n",
        "\n",
        "df_cm_cnn = pd.DataFrame(cf_matrix_cnn, columns=np.unique(clases), index = np.unique(clases))\n",
        "df_cm_cnn.index.name = 'Actual'\n",
        "df_cm_cnn.columns.name = 'Predicted CNN'\n",
        "\n",
        "columns = {}\n",
        "columns['Actual'] = true_test\n",
        "columns['Predicted SVM'] = svm_result\n",
        "columns['Predicted CNN'] = cnn_result\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(df_cm_svm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16}, fmt='g',ax=ax)# font size\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(df_cm_gs, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16}, fmt='g',ax=ax)# font size\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(df_cm_cnn, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16}, fmt='g',ax=ax)# font size\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}